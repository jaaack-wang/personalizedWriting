{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33184d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f2c4dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AV_models\t\t\t      README.md\n",
      "create_summaries_for_eval_samples.py  requirements.txt\n",
      "create_summaries.sh\t\t      scripts\n",
      "dataset_prepare\t\t\t      train_and_eval_an_AV_model.py\n",
      "notebooks\t\t\t      train_AV_classifiers.sh\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77346b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting generate_llm_writing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile generate_llm_writing.py\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scripts.utils import get_completion\n",
    "\n",
    "from scripts.utils import (\n",
    "    count_words,\n",
    "    round_up_to_nearest_10,\n",
    "    list_writing_samples\n",
    ")\n",
    "\n",
    "from scripts.prompt_templates import (\n",
    " get_prompt_template_for_writing_setting1, \n",
    " get_prompt_template_for_writing_setting4   \n",
    ")\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description=\"Create writing prompts and prompt LLMs to generate writing.\")\n",
    "    parser.add_argument(\"--evaluation_df_fp\", type=str, required=True, help=\"Path to the evaluation DataFrame.\")\n",
    "    parser.add_argument(\"--llm\", type=str, required=True, help=\"LLM model to use for generation. Use litellm name convention.\")\n",
    "\n",
    "    parser.add_argument(\"--training_df_fp\", type=str, default=None, help=\"Path to the training DataFrame. Default is None.\")\n",
    "    parser.add_argument(\"--setting\", type=int, choices=[1, 2, 3, 4, 5], default=1, help=\"Prompt setting (1-5). Default is 1.\")\n",
    "    parser.add_argument(\"--genre\", type=str, default=None, help=\"Genre of the writing samples. Default is None (auto infer from dataset if possible).\")\n",
    "    parser.add_argument(\"--author_col\", type=str, default=\"author\", help=\"Column name for author in the DataFrame. Default is 'author'.\")\n",
    "    parser.add_argument(\"--text_col\", type=str, default=\"text\", help=\"Column name for text in the DataFrame. Default is 'text'.\")\n",
    "    parser.add_argument(\"--summary_col\", type=str, default=\"summary\", help=\"Column name for summary in the DataFrame. Default is 'summary'.\")\n",
    "    parser.add_argument(\"--num_exemplars\", type=int, default=5, help=\"Number of exemplars per author. Default is 5.\")\n",
    "    \n",
    "    parser.add_argument(\"--temperature\", type=float, default=0, help=\"Temperature for the LLM. Default is 0.\")\n",
    "    parser.add_argument(\"--max_tries\", type=int, default=5, help=\"Number of tries for LLM completion. Default is 5.\")\n",
    "    parser.add_argument(\"--save_freq\", type=int, default=10, help=\"Frequency of saving LLM outputs. Default is 10.\")\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def create_writing_prompts_setting1(training_df_fp, \n",
    "                                    evaluation_df_fp, \n",
    "                                    genre,\n",
    "                                    author_col=\"author\", \n",
    "                                    text_col=\"text\", \n",
    "                                    summary_col=\"summary\", \n",
    "                                    num_exemplars=5):\n",
    "    \n",
    "    training_df = pd.read_csv(training_df_fp)\n",
    "    evaluation_df = pd.read_csv(evaluation_df_fp)\n",
    "\n",
    "    assert training_df[author_col].value_counts().min() >= num_exemplars, \\\n",
    "        f\"Each author must have at least {num_exemplars} samples in the training set.\"\n",
    "    \n",
    "    assert summary_col in evaluation_df.columns, \\\n",
    "        f\"Summary column '{summary_col}' not found in evaluation DataFrame.\"\n",
    "\n",
    "    evaluation_df = evaluation_df.copy()\n",
    "    prompt_tmp = get_prompt_template_for_writing_setting1()        \n",
    "    \n",
    "    print(f\"Generating prompts...\")\n",
    "    for ix, row in tqdm(evaluation_df.iterrows(), total=len(evaluation_df)):\n",
    "        \n",
    "        author = row[author_col]\n",
    "        summary = row[summary_col]\n",
    "        \n",
    "        num_words = round_up_to_nearest_10(count_words(row[text_col]))\n",
    "        samples = training_df[training_df[author_col]==author][text_col].sample(num_exemplars)\n",
    "        writing_samples = list_writing_samples(samples)\n",
    "        prompt = prompt_tmp.substitute(writing_samples=writing_samples, \n",
    "                                       genre=genre, num_words=num_words,\n",
    "                                       summary=summary)\n",
    "        evaluation_df.at[ix, \"training sample indices\"] = \",\".join([str(ix) for ix in samples.index])\n",
    "        evaluation_df.at[ix, \"prompt\"] = prompt\n",
    "\n",
    "    evaluation_df.to_csv(evaluation_df_fp, index=False)\n",
    "    \n",
    "    return evaluation_df\n",
    "\n",
    "\n",
    "def create_writing_prompts_setting4(evaluation_df_fp, \n",
    "                                    genre,\n",
    "                                    text_col=\"text\", \n",
    "                                    summary_col=\"summary\"):\n",
    "    \n",
    "    evaluation_df = pd.read_csv(evaluation_df_fp)\n",
    "\n",
    "    assert summary_col in evaluation_df.columns, \\\n",
    "        f\"Summary column '{summary_col}' not found in evaluation DataFrame.\"\n",
    "    \n",
    "    evaluation_df = evaluation_df.copy()\n",
    "    prompt_tmp = get_prompt_template_for_writing_setting4()\n",
    "    \n",
    "    print(f\"Generating prompts...\")\n",
    "    for ix, row in tqdm(evaluation_df.iterrows(), total=len(evaluation_df)):\n",
    "        summary = row[summary_col]\n",
    "        \n",
    "        num_words = round_up_to_nearest_10(count_words(row[text_col]))\n",
    "        prompt = prompt_tmp.substitute(genre=genre, num_words=num_words,\n",
    "                                       summary=summary)\n",
    "        evaluation_df.at[ix, \"prompt\"] = prompt\n",
    "\n",
    "    evaluation_df.to_csv(evaluation_df_fp, index=False)\n",
    "\n",
    "    return evaluation_df\n",
    "\n",
    "\n",
    "def generate_or_load_writing_prompts(args, dire):\n",
    "    if os.path.exists(os.path.join(dire, \"prompts.csv\")):\n",
    "        print(f\"Prompts already exist in {dire}/prompts.csv\")\n",
    "        df = pd.read_csv(os.path.join(dire, \"prompts.csv\"))\n",
    "\n",
    "        return df\n",
    "    \n",
    "    if args.setting == 1:\n",
    "\n",
    "        assert args.training_df_fp is not None, \\\n",
    "            \"Training DataFrame path is required for setting 1.\"\n",
    "        \n",
    "        df = create_writing_prompts_setting1(\n",
    "            training_df_fp=args.training_df_fp,\n",
    "            evaluation_df_fp=args.evaluation_df_fp,\n",
    "            genre=args.genre,\n",
    "            author_col=args.author_col,\n",
    "            text_col=args.text_col,\n",
    "            summary_col=args.summary_col,\n",
    "            num_exemplars=args.num_exemplars\n",
    "        )\n",
    "\n",
    "    elif args.setting == 4:\n",
    "        df = create_writing_prompts_setting4(\n",
    "            evaluation_df_fp=args.evaluation_df_fp,\n",
    "            genre=args.genre,\n",
    "            text_col=args.text_col,\n",
    "            summary_col=args.summary_col\n",
    "        )\n",
    "    else:\n",
    "\n",
    "        raise ValueError(\"Setting not implemented yet.\")\n",
    "    \n",
    "    df.to_csv(os.path.join(dire, \"prompts.csv\"), index=False)\n",
    "    print(f\"Prompts saved to {dire}/prompts.csv\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def prompt_llm_to_generate_writing(df, save_dir, model, \n",
    "                                   temperature=0, max_tries=5, \n",
    "                                   save_freq=10):\n",
    "    model_name = model.split(\"/\")[-1]\n",
    "    fp = os.path.join(save_dir, model_name + \".csv\")\n",
    "\n",
    "    if os.path.exists(fp):\n",
    "        llm_df = pd.read_csv(fp)\n",
    "\n",
    "        if len(llm_df) == len(df):\n",
    "            print(f\"Writing already generated for {model_name}.\")\n",
    "            return\n",
    "        else:\n",
    "            print(f\"Writing generation interrupted for {model_name}. Continuing from {len(llm_df)}.\")\n",
    "            indices = list(range(len(llm_df), len(df)))\n",
    "    else:\n",
    "        indices = list(range(len(df)))\n",
    "        llm_df = pd.DataFrame(columns=[\"writing\"])\n",
    "    \n",
    "    for j, ix in tqdm(enumerate(indices), total=len(indices)):\n",
    "        prompt = df.at[ix, \"prompt\"]\n",
    "        completion = get_completion(prompt, model=model, \n",
    "                                    temperature=temperature, \n",
    "                                    max_tries=max_tries)\n",
    "        llm_df.at[ix, \"writing\"] = completion\n",
    "\n",
    "        if (j+1) % save_freq == 0:\n",
    "            llm_df.to_csv(fp, index=False)\n",
    "    \n",
    "    llm_df.to_csv(fp, index=False)\n",
    "    print(f\"Writing generated and saved to {fp}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    args = get_args()\n",
    "    print(args)\n",
    "    \n",
    "    dataset = args.evaluation_df_fp.split(\"/\")[-1].split(\".\")[0].split(\"_\")[0]\n",
    "    dire = f\"LLM_writing/Setting{args.setting}/{dataset}\"\n",
    "    os.makedirs(dire, exist_ok=True)\n",
    "\n",
    "    if args.training_df_fp is not None:\n",
    "        dataset_ = args.training_df_fp.split(\"/\")[-1].split(\".\")[0].split(\"_\")[0]\n",
    "        assert dataset == dataset_, \\\n",
    "            f\"Training and evaluation datasets must be the same. {dataset} != {dataset_}\"\n",
    "\n",
    "    if args.genre is None:\n",
    "        if dataset.startswith(\"blog\"):\n",
    "            args.genre = \"blog post\"\n",
    "        elif dataset.startswith(\"enron\"):\n",
    "            args.genre = \"email\"\n",
    "        elif dataset.startswith(\"reddit\"):\n",
    "            args.genre = \"reddit post\"\n",
    "        elif dataset.startswith(\"CCAT50\"):\n",
    "            args.genre = \"news article\"\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown dataset: {dataset}. Please specify a genre.\")\n",
    "\n",
    "    #### generating or loading prompts\n",
    "    df = generate_or_load_writing_prompts(args, dire)\n",
    "\n",
    "    #### prompting llm to generate writing\n",
    "    prompt_llm_to_generate_writing(\n",
    "        df, \n",
    "        save_dir=dire, \n",
    "        model=args.llm,\n",
    "        temperature=args.temperature,\n",
    "        max_tries=args.max_tries,\n",
    "        save_freq=args.save_freq\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3599f469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4.1-mini-2025-04-14  gpt-4.1-mini-2025-04-14.csv  prompts.csv\n"
     ]
    }
   ],
   "source": [
    "!ls LLM_writing/Setting1/toy_test_with_summaries/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c015b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>file_name</th>\n",
       "      <th>subject</th>\n",
       "      <th>index</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>summary</th>\n",
       "      <th>training sample indices</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blog</td>\n",
       "      <td>15365</td>\n",
       "      <td>'Bathrooms, hallway corners, laundr...</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>female</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>28,July,2004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Choose accessible locations like bathrooms, ha...</td>\n",
       "      <td>3,1,4,2,0</td>\n",
       "      <td>Given the following summary, your task is to g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blog</td>\n",
       "      <td>15365</td>\n",
       "      <td>urlLink June 2003 Outlook from Moonsur...</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>female</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>07,June,2004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Gemini New Moon on May 30th, 2003, marks a...</td>\n",
       "      <td>4,1,0,2,3</td>\n",
       "      <td>Given the following summary, your task is to g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blog</td>\n",
       "      <td>15365</td>\n",
       "      <td>urlLink SAGITTARIUS LUNAR CYCLE  by Cl...</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>female</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>07,June,2004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Sagittarius lunar cycle, marked by a total...</td>\n",
       "      <td>4,0,1,2,3</td>\n",
       "      <td>Given the following summary, your task is to g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blog</td>\n",
       "      <td>15365</td>\n",
       "      <td>The Beatles Title: Let It Be (Lennon, M...</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>female</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>12,October,2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Let It Be\" by The Beatles is a song expressin...</td>\n",
       "      <td>1,0,4,3,2</td>\n",
       "      <td>Given the following summary, your task is to g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blog</td>\n",
       "      <td>15365</td>\n",
       "      <td>THE MOON WAS STILL UP   Anger and pain I c...</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>female</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>14,September,2003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The text explores deep emotions of anger and p...</td>\n",
       "      <td>3,1,0,2,4</td>\n",
       "      <td>Given the following summary, your task is to g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>reddit</td>\n",
       "      <td>wonderfuldog</td>\n",
       "      <td>Occam's Razor]( \\n A guy is found  dead of a g...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>446467.0</td>\n",
       "      <td>atheism</td>\n",
       "      <td>The text explains Occam's Razor by comparing t...</td>\n",
       "      <td>399,396,395,397,398</td>\n",
       "      <td>Given the following summary, your task is to g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>reddit</td>\n",
       "      <td>wonderfuldog</td>\n",
       "      <td>If we lived side-by-side with dinosaurs, don't...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>849514.0</td>\n",
       "      <td>atheism</td>\n",
       "      <td>The text questions why, if humans lived alongs...</td>\n",
       "      <td>399,395,398,397,396</td>\n",
       "      <td>Given the following summary, your task is to g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>reddit</td>\n",
       "      <td>wonderfuldog</td>\n",
       "      <td>it means different things to different people ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1242640.0</td>\n",
       "      <td>atheism</td>\n",
       "      <td>The text emphasizes the importance of a shared...</td>\n",
       "      <td>397,399,398,395,396</td>\n",
       "      <td>Given the following summary, your task is to g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>reddit</td>\n",
       "      <td>wonderfuldog</td>\n",
       "      <td>Do you think there is any truth to people sayi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>609221.0</td>\n",
       "      <td>atheism</td>\n",
       "      <td>The text addresses the criticism that r/atheis...</td>\n",
       "      <td>396,398,399,397,395</td>\n",
       "      <td>Given the following summary, your task is to g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>reddit</td>\n",
       "      <td>wonderfuldog</td>\n",
       "      <td>That quote is not cited in  the Wikipedia arti...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>827870.0</td>\n",
       "      <td>atheism</td>\n",
       "      <td>An anonymous user with the IP address 70.89.19...</td>\n",
       "      <td>398,396,395,397,399</td>\n",
       "      <td>Given the following summary, your task is to g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset        author                                               text  \\\n",
       "0      blog         15365             'Bathrooms, hallway corners, laundr...   \n",
       "1      blog         15365          urlLink June 2003 Outlook from Moonsur...   \n",
       "2      blog         15365          urlLink SAGITTARIUS LUNAR CYCLE  by Cl...   \n",
       "3      blog         15365         The Beatles Title: Let It Be (Lennon, M...   \n",
       "4      blog         15365      THE MOON WAS STILL UP   Anger and pain I c...   \n",
       "..      ...           ...                                                ...   \n",
       "395  reddit  wonderfuldog  Occam's Razor]( \\n A guy is found  dead of a g...   \n",
       "396  reddit  wonderfuldog  If we lived side-by-side with dinosaurs, don't...   \n",
       "397  reddit  wonderfuldog  it means different things to different people ...   \n",
       "398  reddit  wonderfuldog  Do you think there is any truth to people sayi...   \n",
       "399  reddit  wonderfuldog  That quote is not cited in  the Wikipedia arti...   \n",
       "\n",
       "      topic  gender   age    sign               date file_name subject  \\\n",
       "0    indUnk  female  34.0  Cancer       28,July,2004       NaN     NaN   \n",
       "1    indUnk  female  34.0  Cancer       07,June,2004       NaN     NaN   \n",
       "2    indUnk  female  34.0  Cancer       07,June,2004       NaN     NaN   \n",
       "3    indUnk  female  34.0  Cancer    12,October,2002       NaN     NaN   \n",
       "4    indUnk  female  34.0  Cancer  14,September,2003       NaN     NaN   \n",
       "..      ...     ...   ...     ...                ...       ...     ...   \n",
       "395     NaN     NaN   NaN     NaN                NaN       NaN     NaN   \n",
       "396     NaN     NaN   NaN     NaN                NaN       NaN     NaN   \n",
       "397     NaN     NaN   NaN     NaN                NaN       NaN     NaN   \n",
       "398     NaN     NaN   NaN     NaN                NaN       NaN     NaN   \n",
       "399     NaN     NaN   NaN     NaN                NaN       NaN     NaN   \n",
       "\n",
       "         index subreddit                                            summary  \\\n",
       "0          NaN       NaN  Choose accessible locations like bathrooms, ha...   \n",
       "1          NaN       NaN  The Gemini New Moon on May 30th, 2003, marks a...   \n",
       "2          NaN       NaN  The Sagittarius lunar cycle, marked by a total...   \n",
       "3          NaN       NaN  \"Let It Be\" by The Beatles is a song expressin...   \n",
       "4          NaN       NaN  The text explores deep emotions of anger and p...   \n",
       "..         ...       ...                                                ...   \n",
       "395   446467.0   atheism  The text explains Occam's Razor by comparing t...   \n",
       "396   849514.0   atheism  The text questions why, if humans lived alongs...   \n",
       "397  1242640.0   atheism  The text emphasizes the importance of a shared...   \n",
       "398   609221.0   atheism  The text addresses the criticism that r/atheis...   \n",
       "399   827870.0   atheism  An anonymous user with the IP address 70.89.19...   \n",
       "\n",
       "    training sample indices                                             prompt  \n",
       "0                 3,1,4,2,0  Given the following summary, your task is to g...  \n",
       "1                 4,1,0,2,3  Given the following summary, your task is to g...  \n",
       "2                 4,0,1,2,3  Given the following summary, your task is to g...  \n",
       "3                 1,0,4,3,2  Given the following summary, your task is to g...  \n",
       "4                 3,1,0,2,4  Given the following summary, your task is to g...  \n",
       "..                      ...                                                ...  \n",
       "395     399,396,395,397,398  Given the following summary, your task is to g...  \n",
       "396     399,395,398,397,396  Given the following summary, your task is to g...  \n",
       "397     397,399,398,395,396  Given the following summary, your task is to g...  \n",
       "398     396,398,399,397,395  Given the following summary, your task is to g...  \n",
       "399     398,396,395,397,399  Given the following summary, your task is to g...  \n",
       "\n",
       "[400 rows x 15 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "p = pd.read_csv(\"LLM_writing/Setting1/blog/prompts.csv\")\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "071e85e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the following summary, your task is to generate a writing sample around 1200 words. The genre of the writing is mixed. Do not output anything other than the writing.\n",
      "\n",
      "### Writing Task Summary\n",
      "\n",
      "The writer reflects on a mixed day, celebrating a small personal victory but frustrated by a broker’s fax error that wasted time. They enjoyed a longer lunch and took advantage of a book sale. The writer comments on a news story about a woman fraudulently posing as a missing girl and criticizes the family’s insensitive reaction caught on camera. They mention Adam’s risky bullfighting job and hope for good worker’s compensation. The writer updates friends on various topics: emails sent to Jan, a funny but sad falling squirrel incident, hair loss advice from Kevin, and sympathy for Jen’s protein issues. They express enthusiasm for Swedish meatballs and possibly having stroganoff for dinner, and congratulate Jen on weight loss. The writer discusses TV show updates, TiVo equipment challenges, and frustration over a new California surcharge affecting higher earners and students. They propose a blog group road trip and share humorous exchanges about squirrels and PMS-related jokes. Plans to build a home in Texas on family land are mentioned, along with reflections on housing affordability differences between Arizona and the current location. The writer also recalls a past “Betty Crocker” dinner tradition with an ex.\n",
      "\n",
      "Begin your response below:\n"
     ]
    }
   ],
   "source": [
    "print(p.sample(1)[\"prompt\"].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ddba4c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>writing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>**Title: A Surprising Visit to Alltel: More Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As we look back at the early 2000s, the landsc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>**The Fine Line Between Safety and Overreactio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Title: Cats, Communism, and the Conservative C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ah, the beach! There’s something magical about...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>As I sit here, the pages of my book blur toget...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>**The Lesson of the Stolen Bike: A Journey of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>**Homecoming: The Return of Cardinal John Henr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Hey there, fabulous readers! \\n\\nFirst off, a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Flying out of Charles de Gaulle Airport in Jan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               writing\n",
       "0    **Title: A Surprising Visit to Alltel: More Th...\n",
       "1    As we look back at the early 2000s, the landsc...\n",
       "2    **The Fine Line Between Safety and Overreactio...\n",
       "3    Title: Cats, Communism, and the Conservative C...\n",
       "4    Ah, the beach! There’s something magical about...\n",
       "..                                                 ...\n",
       "195  As I sit here, the pages of my book blur toget...\n",
       "196  **The Lesson of the Stolen Bike: A Journey of ...\n",
       "197  **Homecoming: The Return of Cardinal John Henr...\n",
       "198  Hey there, fabulous readers! \\n\\nFirst off, a ...\n",
       "199  Flying out of Charles de Gaulle Airport in Jan...\n",
       "\n",
       "[200 rows x 1 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.read_csv(\"LLM_writing/Setting4/blog/gpt-4o-mini-2024-07-18.csv\")\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2888e84a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>writing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>so it’s that time again, my monthly pilgrimage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Future of IT Jobs: A Growing Concern  \\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The recent nightclub fire has everyone buzzing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oh wow, here we go again! *sigh* So, I’ve been...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ah, the beach! what a delightful escape! the w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Girlchick911: so like, can you believe Jen wan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Breaking News: A Harvard Law Student Wins Miss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>So, last night was a whirlwind, and I’m feelin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Oh my gosh, you guys! You will NOT believe wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Worship can easily slip into a routine, can’t ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              writing\n",
       "0   so it’s that time again, my monthly pilgrimage...\n",
       "1   The Future of IT Jobs: A Growing Concern  \\n\\n...\n",
       "2   The recent nightclub fire has everyone buzzing...\n",
       "3   Oh wow, here we go again! *sigh* So, I’ve been...\n",
       "4   ah, the beach! what a delightful escape! the w...\n",
       "..                                                ...\n",
       "95  Girlchick911: so like, can you believe Jen wan...\n",
       "96  Breaking News: A Harvard Law Student Wins Miss...\n",
       "97  So, last night was a whirlwind, and I’m feelin...\n",
       "98  Oh my gosh, you guys! You will NOT believe wha...\n",
       "99  Worship can easily slip into a routine, can’t ...\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.read_csv(\"LLM_writing/Setting1/blog/gpt-4o-mini-2024-07-18.csv\")\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69739e33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76c07c70",
   "metadata": {},
   "source": [
    "- LLM_writing\n",
    "\n",
    "    - Setting1\n",
    "        - dataset1\n",
    "            - prompts.csv\n",
    "            - llm1.csv\n",
    "            - llm2.csv\n",
    "            - ...\n",
    "        - dataset2\n",
    "            - prompts.csv\n",
    "            - llm1.csv\n",
    "            - llm2.csv\n",
    "            - ...\n",
    "        - dataset3\n",
    "            - prompts.csv\n",
    "            - llm1.csv\n",
    "            - llm2.csv\n",
    "            - ...\n",
    "        - dataset4\n",
    "            - prompts.csv\n",
    "            - llm1.csv\n",
    "            - llm2.csv\n",
    "            - ...\n",
    "    - Setting2\n",
    "    - Setting3\n",
    "    - Setting4\n",
    "    - Setting5\n",
    "    - Setting1_followup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369a1ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb32e27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
