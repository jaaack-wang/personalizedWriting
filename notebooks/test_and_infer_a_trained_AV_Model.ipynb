{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b9c87bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jack/anaconda3/envs/PW/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-04-27 18:42:44.312600: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745793764.324282 1916977 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745793764.327953 1916977 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1745793764.338779 1916977 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745793764.338793 1916977 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745793764.338794 1916977 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745793764.338795 1916977 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-27 18:42:44.342397: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import Trainer, AutoModelForSequenceClassification\n",
    "\n",
    "\n",
    "def get_text_encodings(model_name, texts1, texts2, max_length):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    return tokenizer(texts1, texts2, \n",
    "                     truncation=True, \n",
    "                     padding=\"max_length\", \n",
    "                     max_length=max_length)\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) \n",
    "                for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "def get_dataset(model_name, texts1, texts2,\n",
    "                max_length, labels):\n",
    "    \n",
    "    encodings = get_text_encodings(model_name, \n",
    "                                   texts1, texts2, \n",
    "                                   max_length)\n",
    "\n",
    "    dataset = CustomDataset(encodings, labels)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def get_model_and_trainer(model_load_file):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_load_file)\n",
    "    trainer = Trainer(model=model)\n",
    "    return model, trainer\n",
    "\n",
    "\n",
    "def print_classification_report(y_test, y_pred):\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "\n",
    "def sanity_check_av_ckpt_dir(ckpt_dir, test_set_fp=None, \n",
    "                             test_on_samples=False, samples_size=1000):\n",
    "    ckpt_dir_parent = os.path.dirname(ckpt_dir)\n",
    "\n",
    "    with open(os.path.join(ckpt_dir_parent, \"args.json\"), \"r\") as f:\n",
    "        args = json.load(f)\n",
    "    \n",
    "    model_name = args[\"model_name\"]\n",
    "    max_length = args[\"max_length\"]\n",
    "    if test_set_fp is None:\n",
    "        test_set_fp = os.path.join(args[\"data_dir\"], \"test.csv\")\n",
    "    \n",
    "    test_set_fp = \"../\" + args[\"data_dir\"] + \"/test.csv\"\n",
    "    df = pd.read_csv(test_set_fp)\n",
    "\n",
    "    if test_on_samples:\n",
    "        df = df.sample(samples_size, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    labels = df[\"label\"].tolist()\n",
    "    dataset = get_dataset(model_name, df[\"text1\"].tolist(), \n",
    "                          df[\"text2\"].tolist(), max_length, labels)\n",
    "    \n",
    "    model, trainer = get_model_and_trainer(ckpt_dir)\n",
    "    predictions = trainer.predict(dataset)\n",
    "    y_pred = predictions.predictions.argmax(-1)\n",
    "\n",
    "    model_name = model_name.split('/')[-1]\n",
    "    prev_y_pred = df[f\"{model_name}-prediction\"]\n",
    "    overlap = (y_pred == prev_y_pred).mean()\n",
    "    print(f\"Overlap: {overlap:.2f}\")\n",
    "\n",
    "    print_classification_report(y_pred, labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07030f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlap: 1.00\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.75      0.80       692\n",
      "           1       0.56      0.71      0.63       308\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.71      0.73      0.71      1000\n",
      "weighted avg       0.76      0.74      0.75      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ckpt_dir = \"../AV_models/bert-base-uncased/blog_AV_datasets/checkpoint-125\"\n",
    "sanity_check_av_ckpt_dir(ckpt_dir, test_set_fp=None, \n",
    "                         test_on_samples=True, samples_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75e75fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing global attention on CLS token...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlap: 1.00\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.75      0.76       610\n",
      "           1       0.62      0.64      0.63       390\n",
      "\n",
      "    accuracy                           0.71      1000\n",
      "   macro avg       0.69      0.70      0.69      1000\n",
      "weighted avg       0.71      0.71      0.71      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ckpt_dir = \"../AV_models/longformer-base-4096/enron_AV_datasets/checkpoint-250\"\n",
    "sanity_check_av_ckpt_dir(ckpt_dir, test_set_fp=None, \n",
    "                         test_on_samples=True, samples_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f38ea59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlap: 1.00\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.69      0.80       851\n",
      "           1       0.32      0.83      0.46       149\n",
      "\n",
      "    accuracy                           0.71      1000\n",
      "   macro avg       0.64      0.76      0.63      1000\n",
      "weighted avg       0.86      0.71      0.75      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ckpt_dir = \"../AV_models/ModernBERT-base/blog_AV_datasets/checkpoint-250\"\n",
    "sanity_check_av_ckpt_dir(ckpt_dir, test_set_fp=None, \n",
    "                         test_on_samples=True, samples_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04544316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966ddf2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e72c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# infer_AV.py\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.nn.functional import softmax\n",
    "from transformers import Trainer, AutoModelForSequenceClassification\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description=\"Inference script for AV model\")\n",
    "    parser.add_argument(\"--ckpt_dir\", type=str, required=True, help=\"Directory containing the model checkpoint\")\n",
    "    parser.add_argument(\"--LLM_writing_dir_or_subdir\", type=str, required=True, default=\"LLM_writing\", \n",
    "                        help=\"LLM writing directory or subdirectory\")\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def get_text_encodings(model_name, texts1, texts2, max_length):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    return tokenizer(texts1, texts2, \n",
    "                     truncation=True, \n",
    "                     padding=\"max_length\", \n",
    "                     max_length=max_length)\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) \n",
    "                for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "def get_dataset(model_name, texts1, texts2,\n",
    "                max_length, labels):\n",
    "    \n",
    "    encodings = get_text_encodings(model_name, \n",
    "                                   texts1, texts2, \n",
    "                                   max_length)\n",
    "\n",
    "    dataset = CustomDataset(encodings, labels)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def get_model_and_trainer(ckpt_dir):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(ckpt_dir)\n",
    "    trainer = Trainer(model=model)\n",
    "    return model, trainer\n",
    "\n",
    "\n",
    "def print_classification_report(y_test, y_pred):\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "\n",
    "def find_directories_with_file(root_dir, target_filename):\n",
    "    matching_dirs = []\n",
    "\n",
    "    for dirpath, _, filenames in os.walk(root_dir, topdown=False):\n",
    "        if target_filename in filenames:\n",
    "            matching_dirs.append(dirpath)\n",
    "\n",
    "    return matching_dirs\n",
    "\n",
    "\n",
    "def main():\n",
    "    args = get_args()\n",
    "    print(args)\n",
    "\n",
    "    ckpt_dir_parent = os.path.dirname(args.ckpt_dir)\n",
    "    with open(os.path.join(ckpt_dir_parent, \"args.json\"), \"r\") as f:\n",
    "        args_dict = json.load(f)\n",
    "    \n",
    "    model, trainer = get_model_and_trainer(ckpt_dir)\n",
    "    \n",
    "    model_name = args_dict[\"model_name\"]\n",
    "    max_length = args_dict[\"max_length\"]\n",
    "    llm_dir = args.LLM_writing_dir_or_subdir\n",
    "\n",
    "    dires_to_run = find_directories_with_file(llm_dir, \"prompts.csv\")\n",
    "    for dire in dires_to_run:\n",
    "        prompts_df = pd.read_csv(os.path.join(dire, \"prompts.csv\"))\n",
    "        authors_texts = prompts_df[\"text\"].tolist()\n",
    "        \n",
    "        for llm_fp in os.listdir(dire):\n",
    "            if llm_fp.endswith(\".csv\") and llm_fp != \"prompts.csv\":\n",
    "                llm_df = pd.read_csv(os.path.join(dire, llm_fp))\n",
    "\n",
    "                if f\"{model_name}-prediction\" in llm_df.columns:\n",
    "                    print(f\"Already processed {llm_fp} in {dire}\")\n",
    "                    continue\n",
    "\n",
    "                llm_texts = llm_df[\"writing\"].tolist()\n",
    "\n",
    "                if len(authors_texts) != len(llm_texts):\n",
    "                    print(f\"Length mismatch in {llm_fp} in {dire}\")\n",
    "                    continue\n",
    "                    \n",
    "                \n",
    "                labels = [0] * len(llm_texts)\n",
    "                dataset = get_dataset(model_name, authors_texts, \n",
    "                                      llm_texts, max_length, labels)\n",
    "                predictions = trainer.predict(dataset)\n",
    "                y_pred = predictions.predictions.argmax(-1)\n",
    "                logits = predictions.predictions  # This contains the raw logits output\n",
    "                # Convert logits to probabilities using softmax\n",
    "                probabilities = softmax(torch.tensor(logits), dim=1).tolist()\n",
    "                llm_df[f\"{model_name}-prediction\"]=y_pred\n",
    "                llm_df[f\"{model_name}-probabilities\"] = [prob[1] for prob in probabilities]\n",
    "                llm_df.to_csv(os.path.join(dire, llm_fp), index=False)\n",
    "                print(f\"Processed {llm_fp} in {dire}\")\n",
    "                \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7794bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c849f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
