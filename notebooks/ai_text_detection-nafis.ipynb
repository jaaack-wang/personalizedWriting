{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AV2Oqh7sL9i8",
        "outputId": "a9b5bb21-079f-4566-af72-66ae9df59bcd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /Users/nit03/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from glob import glob\n",
        "import shutil\n",
        "import glob\n",
        "import json\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from statistics import stdev\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import codecs\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import csv\n",
        "from sklearn.metrics import classification_report, precision_score,recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsCwpN5zL9jB"
      },
      "source": [
        "# Data splitting for ai text detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkqhiMXdL9jC"
      },
      "outputs": [],
      "source": [
        "def get_label(source):\n",
        "    if source == 'human':\n",
        "        return 0\n",
        "    else:\n",
        "        return 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI_gI8-xL9jD"
      },
      "source": [
        "## reuter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GC3QXsAML9jD",
        "outputId": "29d76ca6-833a-4af6-905f-1f8e8ea922b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['key', 'source', 'intro_text', 'body_text', 'conclusion_text',\n",
              "       'intro_word_count', 'body_word_count', 'conclusion_word_count',\n",
              "       'total_word_count', 'intro_liwc_features', 'body_liwc_features',\n",
              "       'conclusion_liwc_features'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('reuter_equal_length_intact_features.csv')\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAASWD40L9jE",
        "outputId": "8515e0f0-c53a-468e-b7df-19dd4e8ccfaa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5401, 5)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df[['key','source','intro_text','body_text','conclusion_text']]\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "be_vdR1CL9jE",
        "outputId": "3bd78cbe-2875-4988-ba02-2986391c212a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5401, 5)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df.dropna()\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7XkACNoL9jF"
      },
      "outputs": [],
      "source": [
        "df['text'] = df['intro_text'] + ' '+ df['body_text'] + ' ' + df['conclusion_text']\n",
        "df['label'] = df['source'].apply(get_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0SXkYyDL9jF",
        "outputId": "261a28f3-0e1e-4275-c92f-c68c1cd4f88e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "label\n",
              "0     872\n",
              "1    4529\n",
              "dtype: int64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.groupby('label').size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fVghPgGL9jG",
        "outputId": "344ad82c-f142-4326-9d9f-f7320352bf42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2700, 7) (2161, 7) (540, 7)\n"
          ]
        }
      ],
      "source": [
        "train_df , test_df = train_test_split(df,test_size=0.5)\n",
        "valid_df , test_df = train_test_split(test_df, test_size=0.8)\n",
        "print(train_df.shape, test_df.shape, valid_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TR8EabNqL9jG"
      },
      "outputs": [],
      "source": [
        "dataset = 'reuter'\n",
        "train_df.to_csv(dataset+'//'+dataset+'_train.csv',index=False)\n",
        "valid_df.to_csv(dataset+'//'+dataset+'_valid.csv',index=False)\n",
        "test_df.to_csv(dataset+'//'+dataset+'_test.csv',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2Rt-IizL9jG"
      },
      "source": [
        "# Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-i-Il86jL9jG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup\n",
        "from datasets import load_dataset, load_metric\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqINJzN0L9jH",
        "outputId": "009ea1ec-add2-47cf-b265-9afc8fd6dbbd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='mps')"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVkw5csmL9jH",
        "outputId": "3fafb99c-6942-40cf-993d-899eb6954bd2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Load tokenizer and model, move model to MPS if available\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDpAdosxL9jH"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECFVpVW_L9jH"
      },
      "source": [
        "## reuter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-RBTOhsL9jH"
      },
      "outputs": [],
      "source": [
        "dataset = 'reuter'\n",
        "train_df = pd.read_csv(dataset+'//'+dataset+'_train.csv')\n",
        "test_df = pd.read_csv(dataset+'//'+dataset+'_test.csv')\n",
        "valid_df = pd.read_csv(dataset+'//'+dataset+'_valid.csv')\n",
        "train_df = train_df.sample(frac=0.2)\n",
        "valid_df = valid_df.sample(frac=0.2)\n",
        "test_df = test_df.sample(frac=0.2)\n",
        "train_df = train_df.reset_index()\n",
        "valid_df = valid_df.reset_index()\n",
        "test_df = test_df.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdsOiWSgL9jI",
        "outputId": "2d824a6c-4836-49a8-ca1c-cfffcf97656b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>key</th>\n",
              "      <th>source</th>\n",
              "      <th>intro_text</th>\n",
              "      <th>body_text</th>\n",
              "      <th>conclusion_text</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>536</th>\n",
              "      <td>746</td>\n",
              "      <td>KarlPenhaul_17</td>\n",
              "      <td>human</td>\n",
              "      <td>Another member of Colombia's main oil workers'...</td>\n",
              "      <td>USO head Hernando Hernandez said last Thursday...</td>\n",
              "      <td>Mines and Energy Minister Rodrigo Villamizar s...</td>\n",
              "      <td>Another member of Colombia's main oil workers'...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>1569</td>\n",
              "      <td>JaneMacartney_6</td>\n",
              "      <td>llama2_chat</td>\n",
              "      <td>Beijing, China - In a shocking turn of events,...</td>\n",
              "      <td>The sentence was handed down by the Beijing No...</td>\n",
              "      <td>The sentencing of Liu Xiaobo has sent shockwav...</td>\n",
              "      <td>Beijing, China - In a shocking turn of events,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     index              key       source  \\\n",
              "536    746   KarlPenhaul_17        human   \n",
              "48    1569  JaneMacartney_6  llama2_chat   \n",
              "\n",
              "                                            intro_text  \\\n",
              "536  Another member of Colombia's main oil workers'...   \n",
              "48   Beijing, China - In a shocking turn of events,...   \n",
              "\n",
              "                                             body_text  \\\n",
              "536  USO head Hernando Hernandez said last Thursday...   \n",
              "48   The sentence was handed down by the Beijing No...   \n",
              "\n",
              "                                       conclusion_text  \\\n",
              "536  Mines and Energy Minister Rodrigo Villamizar s...   \n",
              "48   The sentencing of Liu Xiaobo has sent shockwav...   \n",
              "\n",
              "                                                  text  label  \n",
              "536  Another member of Colombia's main oil workers'...      0  \n",
              "48   Beijing, China - In a shocking turn of events,...      1  "
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.sample(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zg9WdCijL9jI"
      },
      "outputs": [],
      "source": [
        "train_encodings = tokenizer(list(train_df['text']),truncation=True, padding=\"max_length\",max_length=512)\n",
        "valid_encodings = tokenizer(list(valid_df['text']), truncation=True, padding=\"max_length\",max_length=512)\n",
        "test_encodings = tokenizer(list(test_df['text']),truncation=True, padding=\"max_length\",max_length=512)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3NSZ3C_L9jI"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = CustomDataset(train_encodings, train_df['label'])\n",
        "valid_dataset = CustomDataset(valid_encodings, valid_df['label'])\n",
        "test_dataset = CustomDataset(test_encodings, test_df['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2DcSwRHL9jI"
      },
      "outputs": [],
      "source": [
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43O6UuocL9jI"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "import evaluate  # Make sure to import this\n",
        "def compute_metrics(eval_pred):\n",
        "    f1_score = evaluate.load(\"f1\")\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    f1_score.add_batch(predictions=predictions, references=labels)\n",
        "    return f1_score.compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhA0O8SvL9jI"
      },
      "outputs": [],
      "source": [
        "model_output_dir = dataset + '_trained_models'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "d2962d4d2a7e47b18978ca15cd02de0d",
            "f17e8a57ce064440b5583e3e32b09be7"
          ]
        },
        "id": "oW0tLWVAL9jI",
        "outputId": "a0d3aae6-29f2-4ba8-837f-8952996db300"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2962d4d2a7e47b18978ca15cd02de0d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/675 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 2e-05, 'epoch': 0.74}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f17e8a57ce064440b5583e3e32b09be7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': nan, 'eval_f1': 0.0, 'eval_runtime': 6.0747, 'eval_samples_per_second': 17.779, 'eval_steps_per_second': 1.152, 'epoch': 0.74}\n"
          ]
        }
      ],
      "source": [
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=model_output_dir,  # output directory\n",
        "    num_train_epochs=5,  # total # of training epochs\n",
        "    per_device_train_batch_size=4,  # batch size per device during training\n",
        "    per_device_eval_batch_size=16,  # batch size for evaluation\n",
        "    warmup_steps=100,  # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,  # strength of weight decay\n",
        "    learning_rate=2e-5,  # learning rate\n",
        "    save_total_limit=1,  # limit the total amount of checkpoints, delete older checkpoints\n",
        "    logging_steps=100,\n",
        "    evaluation_strategy=\"steps\",  # evaluate at the end of each epoch\n",
        "    save_strategy=\"steps\",  # save model at the end of each epoch\n",
        "    load_best_model_at_end=True,  # load the best model at the end of training\n",
        "    metric_for_best_model=\"eval_loss\",  # metric to track for early stopping\n",
        "    greater_is_better=False,  # validation loss should decrease\n",
        ")\n",
        "\n",
        "# Create the Trainer object with Early Stopping Callback\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=valid_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],  # Early stopping patience\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
